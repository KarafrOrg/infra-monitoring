object-buckets:
  buckets:
    - name: &tempoTraceBucketName tempo-traces-bucket
      storageClassName: rook-ceph-bucket
      labels:
        app: loki
      pushSecret:
        enabled: true
        secretStoreName: gcp-sm-cluster-secret-store
        secretMappings:
          - secretKey: AWS_ACCESS_KEY_ID
            remoteKey: tempo-traces-bucket-s3-access-key
          - secretKey: AWS_SECRET_ACCESS_KEY
            remoteKey: tempo-traces-bucket-s3-secret-key

tempo:
  enabled: false  # Using tempo-distributed instead
  replicas: 3

  tempo:
    metricsGenerator:
      enabled: true
      remoteWriteUrl: "http://mimir-gateway.infra-monitoring.svc.cluster.local:80/api/v1/push"
      processor:
        service_graphs:
          dimensions: [ ]
        span_metrics:
          dimensions: [ ]
        local_blocks:
          filter_server_spans: false
    extraEnv:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: *tempoTraceBucketName
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: *tempoTraceBucketName
            key: AWS_SECRET_ACCESS_KEY
      - name: TEMPO_S3_BUCKET_NAME
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_NAME
      - name: TEMPO_S3_ENDPOINT
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_HOST
      - name: TEMPO_S3_PORT
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_PORT
    extraArgs:
      config.expand-env: true

    storage:
      trace:
        backend: s3
        s3:
          bucket: ${TEMPO_S3_BUCKET_NAME}
          endpoint: ${TEMPO_S3_ENDPOINT}.cluster.local:${TEMPO_S3_PORT}
          region: us-east-1
          insecure: true
    # Retention and compaction
    compactor:
      compaction:
        block_retention: 168h  # 7 days

    # Ingester configuration
    ingester:
      max_block_duration: 10m
      complete_block_timeout: 15m
      flush_check_period: 5s
      trace_idle_period: 10s

    # Receivers configuration
    receivers:
      otlp:
        protocols:
          http:
            endpoint: 0.0.0.0:4318
          grpc:
            endpoint: 0.0.0.0:4317
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
          thrift_compact:
            endpoint: 0.0.0.0:6831
          thrift_binary:
            endpoint: 0.0.0.0:6832
      zipkin:
        endpoint: 0.0.0.0:9411

    querier:
      max_concurrent_queries: 20

    query_frontend:
      search:
        max_duration: 0
      trace_by_id:
        query_shards: 2

    overrides:
      defaults:
        metrics_generator:
          processors: [ service-graphs, span-metrics, local-blocks ]

  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 2Gi

  # Persistent storage for WAL
  persistence:
    enabled: true
    size: 30Gi
    storageClassName: longhorn

  # Service configuration
  service:
    type: ClusterIP
    port: 3100

  # Enable OTLP receivers
  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true
    jaeger:
      thriftHttp:
        enabled: true
      grpc:
        enabled: true
    zipkin:
      enabled: true

  # Service monitor for Prometheus
  serviceMonitor:
    enabled: true
    interval: 30s

  # Pod annotations
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "3100"

  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 10001
    fsGroup: 10001

  # Topology spread for high availability (even in single replica mode)
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: ScheduleAnyway
      labelSelector:
        matchLabels:
          app.kubernetes.io/name: tempo
          app.kubernetes.io/instance: tempo

tempo-distributed:
  enabled: true
  fullnameOverride: tempo-distributed

  global:
    extraEnv:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: *tempoTraceBucketName
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: *tempoTraceBucketName
            key: AWS_SECRET_ACCESS_KEY
      - name: TEMPO_S3_BUCKET_NAME
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_NAME
      - name: TEMPO_S3_ENDPOINT
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_HOST
      - name: TEMPO_S3_PORT
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_PORT
    extraArgs:
      - -config.expand-env=true

  # Storage configuration
  storage:
    trace:
      backend: s3
      s3:
        bucket: ${TEMPO_S3_BUCKET_NAME}
        endpoint: ${TEMPO_S3_ENDPOINT}.cluster.local:${TEMPO_S3_PORT}
        region: us-east-1
        insecure: true
        access_key: ${AWS_ACCESS_KEY_ID}
        secret_key: ${AWS_SECRET_ACCESS_KEY}
      pool:
        max_workers: 400
        queue_depth: 20000
      search:
        prefetch_trace_count: 1000
      blocklist_poll: 5m

  # Ingester configuration
  ingester:
    replicas: 3
    persistence:
      enabled: false  # Using object storage
    config:
      replication_factor: 3
      trace_idle_period: 10s
      flush_check_period: 5s
      max_block_duration: 10m
      complete_block_timeout: 15m
      flush_all_on_shutdown: false
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2Gi

  # Distributor configuration
  distributor:
    replicas: 2
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Compactor configuration with retention
  compactor:
    replicas: 1
    config:
      compaction:
        block_retention: 168h  # 7 days
        compacted_block_retention: 1h
        compaction_window: 1h
        max_block_bytes: 107374182400
        retention_concurrency: 10
        max_time_per_tenant: 5m
        compaction_cycle: 30s
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Querier configuration with query workers enabled
  querier:
    replicas: 2
    config:
      frontend_worker:
        frontend_address: tempo-distributed-query-frontend:9095
        parallelism: 10
      max_concurrent_queries: 20
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Query Frontend configuration
  queryFrontend:
    replicas: 2
    config:
      max_outstanding_per_tenant: 2000
      max_retries: 2
      search:
        concurrent_jobs: 1000
        target_bytes_per_job: 104857600
        max_duration: 0  # No limit
      trace_by_id:
        query_shards: 2
      metrics:
        concurrent_jobs: 1000
        target_bytes_per_job: 104857600
        max_duration: 3h
        query_backend_after: 30m
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Metrics Generator configuration
  metricsGenerator:
    enabled: true
    replicas: 2
    config:
      registry:
        collection_interval: 15s
      processor:
        service_graphs:
          dimensions: []
          histogram_buckets: [0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8]
          max_items: 10000
          wait: 10s
          workers: 10
        span_metrics:
          dimensions: []
          histogram_buckets: [0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512, 1.02, 2.05, 4.10]
      storage:
        path: /var/tempo/wal
        remote_write:
          - url: http://mimir-gateway.infra-monitoring.svc.cluster.local:80/api/v1/push
            send_exemplars: true
        remote_write_add_org_id_header: true
      traces_storage:
        path: /var/tempo/traces
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Gateway configuration
  gateway:
    enabled: true
    replicas: 2
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

  # Overrides for all tenants
  overrides:
    defaults:
      metrics_generator:
        processors: [service-graphs, span-metrics, local-blocks]

  # Memcached configuration
  memcached:
    enabled: true
    replicas: 1
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 100m
        memory: 256Mi

  # Cache configuration
  cache:
    caches:
      - memcached:
          host: tempo-distributed-memcached
          service: memcached-client
          consistent_hash: true
          timeout: 500ms
        roles:
          - parquet-footer
          - bloom
          - frontend-search

  # Disable minio
  minio:
    enabled: false

  # Service monitors
  serviceMonitor:
    enabled: true
    interval: 30s

  # Traces receivers via gateway
  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true
    jaeger:
      thriftHttp:
        enabled: true
      grpc:
        enabled: true
    zipkin:
      enabled: true

