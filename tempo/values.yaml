object-buckets:
  buckets:
    - name: &tempoTraceBucketName tempo-traces-bucket
      storageClassName: rook-ceph-bucket
      labels:
        app: loki
      pushSecret:
        enabled: true
        secretStoreName: gcp-sm-cluster-secret-store
        secretMappings:
          - secretKey: AWS_ACCESS_KEY_ID
            remoteKey: tempo-traces-bucket-s3-access-key
          - secretKey: AWS_SECRET_ACCESS_KEY
            remoteKey: tempo-traces-bucket-s3-secret-key

tempo-distributed:
  enabled: true
  fullnameOverride: tempo-distributed

  global:
    extraEnv:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: *tempoTraceBucketName
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: *tempoTraceBucketName
            key: AWS_SECRET_ACCESS_KEY
      - name: TEMPO_S3_BUCKET_NAME
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_NAME
      - name: TEMPO_S3_ENDPOINT
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_HOST
      - name: TEMPO_S3_PORT
        valueFrom:
          configMapKeyRef:
            name: *tempoTraceBucketName
            key: BUCKET_PORT
    extraArgs:
      - -config.expand-env=true

  # Storage configuration
  storage:
    trace:
      backend: s3
      s3:
        bucket: ${TEMPO_S3_BUCKET_NAME}
        endpoint: ${TEMPO_S3_ENDPOINT}.cluster.local:${TEMPO_S3_PORT}
        region: us-east-1
        insecure: true
        access_key: ${AWS_ACCESS_KEY_ID}
        secret_key: ${AWS_SECRET_ACCESS_KEY}
      pool:
        max_workers: 400
        queue_depth: 20000
      search:
        prefetch_trace_count: 1000
      blocklist_poll: 5m

  # Ingester configuration
  ingester:
    replicas: 3
    persistence:
      enabled: false  # Using object storage
    config:
      replication_factor: 3
      trace_idle_period: 10s
      flush_check_period: 5s
      max_block_duration: 10m
      complete_block_timeout: 15m
      flush_all_on_shutdown: false
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2Gi

  # Distributor configuration
  distributor:
    replicas: 2
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Compactor configuration with retention
  compactor:
    replicas: 1
    config:
      compaction:
        block_retention: 168h  # 7 days
        compacted_block_retention: 1h
        compaction_window: 1h
        max_block_bytes: 107374182400
        retention_concurrency: 10
        max_time_per_tenant: 5m
        compaction_cycle: 30s
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Querier configuration with query workers enabled
  querier:
    replicas: 2
    config:
      frontend_worker:
        frontend_address: tempo-distributed-query-frontend:9095
        parallelism: 10
      max_concurrent_queries: 20
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  # Query Frontend configuration
  queryFrontend:
    replicas: 2
    config:
      max_outstanding_per_tenant: 2000
      max_retries: 2
      search:
        concurrent_jobs: 1000
        target_bytes_per_job: 104857600
        max_duration: 0  # No limit
      trace_by_id:
        query_shards: 2
      metrics:
        concurrent_jobs: 1000
        target_bytes_per_job: 104857600
        max_duration: 3h
        query_backend_after: 30m
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  metricsGenerator:
    enabled: true
    replicas: 2
    config:
      registry:
        collection_interval: 15s
      processor:
        service_graphs:
          dimensions: []
          histogram_buckets: [0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8]
          max_items: 10000
          wait: 10s
          workers: 10
        span_metrics:
          dimensions: []
          histogram_buckets: [0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512, 1.02, 2.05, 4.10]
      storage:
        path: /var/tempo/wal
        remote_write:
          - url: http://mimir-gateway.infra-monitoring.svc.cluster.local:80/api/v1/push
            send_exemplars: true
        remote_write_add_org_id_header: true
      traces_storage:
        path: /var/tempo/traces
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

  gateway:
    enabled: true
    replicas: 2
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

  overrides:
    defaults:
      metrics_generator:
        processors: [service-graphs, span-metrics, local-blocks]

  memcached:
    enabled: false

  cache:
    caches:
      - memcached:
          host: tempo-distributed-memcached
          service: memcached-client
          consistent_hash: true
          timeout: 500ms
        roles:
          - parquet-footer
          - bloom
          - frontend-search

  minio:
    enabled: false

  serviceMonitor:
    enabled: true
    interval: 30s

  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true
    jaeger:
      thriftHttp:
        enabled: true
      grpc:
        enabled: true
    zipkin:
      enabled: true
